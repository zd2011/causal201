{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zd2011/causal201/blob/main/lab10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InHq_1lhX5TI"
      },
      "source": [
        "# Week 10 - Recitation - Instrumental variables\n",
        "\n",
        "author: Judith Abécassis and Élise Dumas with some inspiration from [Matheus Facure Alves](https://matheusfacure.github.io/python-causality-handbook/landing-page.html), [Card (1995)](https://www.nber.org/papers/w4483) and [Verbeek (2004)](https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf).\n",
        "\n",
        "In today's recitation, we will use an instrumental variable to estimate the Average Treatment Effect of schooling on earnings. We will use data from the US National Longitudinal Survey of Young Men. In this panel survey, a group of 3010 men is followed since 1966 (when they were aged 14–24) until 1976 (when all of them started working).\n",
        "\n",
        "We will stay with a very simple model here, but more complex (and accurate) models have been used and published on this dataset by [Card (1995)](https://www.nber.org/papers/w4483) and [Verbeek (2004)](https://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/modern-econometrics.pdf). You are welcome to read the publications if you are interested in the subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t36JeHydXxen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae0d5a2-672f-4b8a-a252-6c3f227b6382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting linearmodels\n",
            "  Downloading linearmodels-4.25-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 4.4 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.4\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from linearmodels) (1.7.3)\n",
            "Collecting pyhdfe>=0.1\n",
            "  Downloading pyhdfe-0.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting property-cached>=1.6.3\n",
            "  Downloading property_cached-1.6.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.7/dist-packages (from linearmodels) (0.12.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from linearmodels) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from linearmodels) (1.21.6)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.7/dist-packages (from linearmodels) (0.5.3)\n",
            "Collecting formulaic\n",
            "  Downloading formulaic-0.5.2-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.7/dist-packages (from linearmodels) (0.29.32)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->linearmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->linearmodels) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->linearmodels) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.8 in /usr/local/lib/python3.7/dist-packages (from formulaic->linearmodels) (0.8.1)\n",
            "Collecting typing-extensions>=4.2.0\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.7/dist-packages (from formulaic->linearmodels) (1.14.1)\n",
            "Collecting graphlib-backport>=1.0.0\n",
            "  Downloading graphlib_backport-1.0.3-py3-none-any.whl (5.1 kB)\n",
            "Collecting interface-meta>=1.2.0\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cached-property>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from formulaic->linearmodels) (1.5.2)\n",
            "Installing collected packages: typing-extensions, interface-meta, graphlib-backport, pyhdfe, property-cached, mypy-extensions, formulaic, linearmodels\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.1.5 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "spacy 3.4.2 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "confection 0.0.3 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed formulaic-0.5.2 graphlib-backport-1.0.3 interface-meta-1.3.0 linearmodels-4.25 mypy-extensions-0.4.3 property-cached-1.6.4 pyhdfe-0.1.0 typing-extensions-4.4.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import scipy.stats as sps\n",
        "import warnings\n",
        "\n",
        "!pip install linearmodels\n",
        "import linearmodels as lm\n",
        "from linearmodels.iv import IV2SLS\n",
        "\n",
        "warnings.filterwarnings(action='once')\n",
        "rg = np.random.default_rng(2907)\n",
        "\n",
        "sns.set_context('poster')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pJWncK0pdWX"
      },
      "source": [
        "# Exercise 1: dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cNEz8-hnX7dP",
        "outputId": "ceb3f075-7a4c-43b5-b906-e43c5be7f321"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nearc2</th>\n",
              "      <th>wage</th>\n",
              "      <th>educ</th>\n",
              "      <th>south</th>\n",
              "      <th>black</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3010.000000</td>\n",
              "      <td>3010.000000</td>\n",
              "      <td>3010.000000</td>\n",
              "      <td>3010.000000</td>\n",
              "      <td>3010.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.440864</td>\n",
              "      <td>577.282392</td>\n",
              "      <td>13.263455</td>\n",
              "      <td>0.403654</td>\n",
              "      <td>0.233555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.496573</td>\n",
              "      <td>262.958302</td>\n",
              "      <td>2.676913</td>\n",
              "      <td>0.490711</td>\n",
              "      <td>0.423162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>394.250000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>537.500000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>708.750000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2404.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            nearc2         wage         educ        south        black\n",
              "count  3010.000000  3010.000000  3010.000000  3010.000000  3010.000000\n",
              "mean      0.440864   577.282392    13.263455     0.403654     0.233555\n",
              "std       0.496573   262.958302     2.676913     0.490711     0.423162\n",
              "min       0.000000   100.000000     1.000000     0.000000     0.000000\n",
              "25%       0.000000   394.250000    12.000000     0.000000     0.000000\n",
              "50%       0.000000   537.500000    13.000000     0.000000     0.000000\n",
              "75%       1.000000   708.750000    16.000000     1.000000     0.000000\n",
              "max       1.000000  2404.000000    18.000000     1.000000     1.000000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Load dataset\n",
        "df = pd.read_csv(\"data_card.csv\")\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Gu_egP_pdWX"
      },
      "source": [
        " Here is the list of available variables : \n",
        " \n",
        " `nearc2`          indicator for whether a subject grew up near a two-year college, 1:yes, 0:no\n",
        " \n",
        " `wage`              subject's wage in cents per hour in 1976\n",
        " \n",
        " `educ`       subject's years of education in 1976\n",
        " \n",
        " `south`        indicator for whether subject lived in the South\n",
        "                      \n",
        " `black`         indicator for whether subject's race is black"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REUHQ_GIpdWX"
      },
      "source": [
        "### 1. What is the treatment? The outcome?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Va2V9LpdWY"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "Treatment is number of years of education (educ); outcome is earning (wage)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8BCSWhopdWY"
      },
      "source": [
        "### 2. Would you say that SUTVA holds? Strong ignorability? Conditional ignorability? Positivity?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpJQw-OSpdWY"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "SUTVA : it is reasonable to think that the \"no interaction\" part holds, (the fact that another individual decided to quit college or continue college is unlikely to affect your personal future earnings). The assumption that there is only one version of treatment is less likely to be true (different majors/minors, different grades, study years completed until the end or no..). (But we will assume it for the rest of the recitation).\n",
        "\n",
        "Strong ignorability : no, it is not reasonable to think that strong ignorability holds. The experiement is not randomized and several confounding variables may exist, including \"baseline ability\", parent socioeconomic situation (if parents are low income, they are less likely to afford college, but also less likely to provide you tools to pass job interviews.).\n",
        "\n",
        "Conditional ignorability : no, it is not reasonable to think that conditional ignorability holds because important confounders such as \"baseline ability\" or parent socioeconomic situation are not available in the dataset. This implies that we cannot use the estimators we used so far for observational data (stratification, matching, S-learner, T-learner, IPW,...).\n",
        "\n",
        "Positivity : I would say that it is reasonable to assume positivity since there is no factor leading an individual to attend or not attend college with probability 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqTGgak1pdWY"
      },
      "source": [
        "### 3. Among the other variables available in the data, can you think of a potential instrumental variable? Does it satisfy relevance? Exclusion restriction? Instrumental unconfoundedness?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1SuNNy6pdWZ"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "Whether or not the individual grew up near a college can be used as an instrument.\n",
        "\n",
        "It is probably linked with the number of years of schoooling since living closer to a college prevents to large costs due to renting an accomodation near college, or transportation; which ensures relevance.\n",
        "\n",
        "We can argue that it is not directly altering future earnings, other than through schooling (there is no direct reason why living near a college provides you with a better or worse wage); which ensures exclusion restriction.\n",
        "\n",
        "Instrumental uncondoundedness is harder to assume, since there may exist some confounding factors of the instrument and the outcome : for instance living in the south, where the density of college is lower, and the density of companies with high average rate is lower as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRG53mySpdWZ"
      },
      "source": [
        "# Exercise 2: years of schooling as a binary variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDNUeNM9pdWZ"
      },
      "source": [
        "For this exercice, we will assume that relevance, exclusion restriction and instrumental unconfoundedness all hold. We will also assume that we are in a linear setting (see lectures). Finally, we will convert the treatment into a binary variable to simplify the estimators."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koFgrwBFpdWZ"
      },
      "source": [
        "### 1. Data preprocessing : convert the treatment into a binary variable (1 if above median, 0 otherwise)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koAjNmuipdWZ",
        "outputId": "d582dbb7-c214-4831-93e0-35987b0d79e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    1521\n",
              "0    1489\n",
              "Name: educ_bin, dtype: int64"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create educ_bin : 1 if educ is above median and 0 otherwise.\n",
        "df_binary = df.assign(educ_bin = np.where(df.educ>= np.median(df.educ), 1,0))\n",
        "df_binary.educ_bin.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0UQpTI5pdWa"
      },
      "source": [
        "### 2. Compute the difference in means. What can you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDC49D1lpdWa",
        "outputId": "f388f298-15c4-4303-c59b-360b16b02188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The difference in means is 110.06.\n"
          ]
        }
      ],
      "source": [
        "diff_mean = np.mean(df_binary.wage[df_binary.educ_bin == 1])- np.mean(df_binary.wage[df_binary.educ_bin == 0])\n",
        "print(f\"The difference in means is {diff_mean.round(2)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPMAlP9LpdWa"
      },
      "source": [
        "What can you conclude?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UprBXnlpdWa"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "Longer schooling seems to be associated with a increase in future earning (about one dollar per hour). But this estimate is not causal (because strong ignorability does not hold)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jevjvzdYpdWa"
      },
      "source": [
        "### 3. Derive the Wald estimator for ATE using your instrumental variable. What can you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aY8cMD4pdWa",
        "outputId": "33bbf1e7-9610-4560-a60d-6d56b355ff60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wald estimator is 1282.4.\n"
          ]
        }
      ],
      "source": [
        "#Compute numerator of Wald estimator. \n",
        "numerator = np.mean(df_binary.wage[df_binary.nearc2 == 1]) - np.mean(df_binary.wage[df_binary.nearc2 == 0])\n",
        "#Compute denominator of Wald estimator. \n",
        "denominator = np.mean(df_binary.educ_bin[df_binary.nearc2 == 1]) - np.mean(df_binary.educ_bin[df_binary.nearc2 == 0])\n",
        "#Print result\n",
        "wald_estimator = numerator/denominator\n",
        "print(f\"Wald estimator is {wald_estimator.round(2)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv7UNtp8pdWa"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "Our estimate of ATE is 12 dollars per hour (which is much more than the one dollar we found by difference in means). It seems that the difference in means tended to underestimate the true effect due to confounding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1VtGSLFpdWb"
      },
      "source": [
        "### 4. Derive the two-stage least squares estimator of ATE. What do you see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCTos1cipdWb",
        "outputId": "96de5f4e-117e-4390-8224-80beeca1bfcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SL2S estimator is 1282.4.\n"
          ]
        }
      ],
      "source": [
        "##First stage : regress treatment on instrument.\n",
        "reg1 = LinearRegression().fit(df_binary[[\"nearc2\"]], df_binary[\"educ_bin\"])\n",
        "\n",
        "##Second stage : regress outcome on the proxy for treatment derived at first stage.\n",
        "\n",
        "#Create a new column containing the proxy for treatment inferred from reg1\n",
        "df_binary = df_binary.assign(t_hat = reg1.predict(df_binary[[\"nearc2\"]]))\n",
        "\n",
        "#Regress outcome on t_hat\n",
        "reg2 = LinearRegression().fit(df_binary[[\"t_hat\"]], df_binary[\"wage\"])\n",
        "\n",
        "#Print the coefficient in front of t_hat\n",
        "print(f\"SL2S estimator is {reg2.coef_[0].round(2)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwA4ABeZpdWb"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "We get exactly the same estimate for ATE!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQNEU_JEpdWb"
      },
      "source": [
        "### 5. Compare your results with Python function IV2SLS from linearmodels package. What do you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAOqOziNpdWb",
        "outputId": "cb45c3bb-f0ed-4a1a-ccfd-9f19a81064fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>IV-2SLS Estimation Summary</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>-4.9264</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>-4.9284</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>       <td>3010</td>       <th>  F-statistic:       </th> <td>6.7980</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, Nov 04 2022</td> <th>  P-value (F-stat)   </th> <td>0.0091</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>15:48:40</td>     <th>  Distribution:      </th> <td>chi2(1)</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cov. Estimator:</th>      <td>unadjusted</td>    <th>                     </th>    <td></td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th></th>                          <td></td>         <th>                     </th>    <td></td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<caption>Parameter Estimates</caption>\n",
              "<tr>\n",
              "      <td></td>     <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th>  <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>     <td>-70.736</td>   <td>248.81</td>   <td>-0.2843</td> <td>0.7762</td>   <td>-558.40</td>  <td>416.93</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>educ_bin</th>  <td>1282.4</td>    <td>491.85</td>   <td>2.6073</td>  <td>0.0091</td>   <td>318.39</td>   <td>2246.4</td> \n",
              "</tr>\n",
              "</table><br/><br/>Endogenous: educ_bin<br/>Instruments: nearc2<br/>Unadjusted Covariance (Homoskedastic)<br/>Debiased: False<br/>id: 0x12d6d7490"
            ],
            "text/plain": [
              "                          IV-2SLS Estimation Summary                          \n",
              "==============================================================================\n",
              "Dep. Variable:                   wage   R-squared:                     -4.9264\n",
              "Estimator:                    IV-2SLS   Adj. R-squared:                -4.9284\n",
              "No. Observations:                3010   F-statistic:                    6.7980\n",
              "Date:                Fri, Nov 04 2022   P-value (F-stat)                0.0091\n",
              "Time:                        15:48:40   Distribution:                  chi2(1)\n",
              "Cov. Estimator:            unadjusted                                         \n",
              "                                                                              \n",
              "                             Parameter Estimates                              \n",
              "==============================================================================\n",
              "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
              "------------------------------------------------------------------------------\n",
              "const         -70.736     248.81    -0.2843     0.7762     -558.40      416.93\n",
              "educ_bin       1282.4     491.85     2.6073     0.0091      318.39      2246.4\n",
              "==============================================================================\n",
              "\n",
              "Endogenous: educ_bin\n",
              "Instruments: nearc2\n",
              "Unadjusted Covariance (Homoskedastic)\n",
              "Debiased: False\n",
              "IVResults, id: 0x12d6d7490"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#We add a constant to the dataset (this is going to be the intercept term of the model)\n",
        "df_binary = df_binary.assign(const = 1)\n",
        "IV2SLS(dependent = df_binary.wage, #outcome\n",
        "       endog = df_binary.educ_bin, #treatment\n",
        "       exog = df_binary.const, #we just add a constant as covariate\n",
        "       instruments = df_binary.nearc2 #Instrument\n",
        "      ).fit(cov_type = \"unadjusted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgHQM7YnpdWb"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "We get exactly the same estimate! This way we also have access to a p-value and a confidence interval (deriving them by hand is very complicated). Our estimate for the ATE is significant (*p* = 0.0091 < 0.05)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Xd1kFGbpdWb"
      },
      "source": [
        "# Exercise 3 : years of schooling as a continuous variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFaVASWfpdWc"
      },
      "source": [
        "For this exercice, we will assume that relevance, exclusion restriction and instrumental unconfoundedness all hold. We will also assume that we are in a linear setting (see lectures). We will use the continuous version of the treatment, as available in the original database (years of schooling)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c53SNETHpdWc"
      },
      "source": [
        "### 1. Derive the Wald estimator for continuous variable. What do you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBfZzFaQpdWc",
        "outputId": "358bd4bb-e449-4d47-c7ea-d040fbe70688"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15.106768288710828\n",
            "0.06294284367274704\n",
            "Wald estimator is 240.01.\n"
          ]
        }
      ],
      "source": [
        "#Compute experimental covariance between Y and Z \n",
        "cov_YZ = np.cov(df.wage, df.nearc2)[1,0]\n",
        "print(cov_YZ)\n",
        "#Compute experimental covariance between T and Z\n",
        "cov_TZ = np.cov(df.educ, df.nearc2)[1,0]\n",
        "print(cov_TZ)\n",
        "#Compute Wald estimator\n",
        "wald_estimator = cov_YZ/cov_TZ\n",
        "print(f\"Wald estimator is {wald_estimator.round(2)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFwMrHKXpdWc"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "Our ATE estimate for continous treatment is 240 cents; meaning that on average each new schooling years increase future earnings by 2.4 dollars/hour. This is consistent with our previous results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJf0xWznpdWc"
      },
      "source": [
        "### 2. Derive the two-stage least squares estimator (SL2S). What can you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFu1VcSBpdWc",
        "outputId": "88709021-bdad-447e-b818-29b64680f42d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SL2S estimator is 240.01.\n"
          ]
        }
      ],
      "source": [
        "##First stage : regress treatment on instrument.\n",
        "reg1 = LinearRegression().fit(df_binary[[\"nearc2\"]], df_binary[\"educ\"])\n",
        "\n",
        "##Second stage : regress outcome on the proxy for treatment derived at first stage.\n",
        "\n",
        "#Create a new column containing the proxy for treatment inferred from reg1\n",
        "df_binary = df_binary.assign(t_hat = reg1.predict(df_binary[[\"nearc2\"]]))\n",
        "\n",
        "#Regress outcome of t_hat\n",
        "reg2 = LinearRegression().fit(df_binary[[\"t_hat\"]], df_binary[\"wage\"])\n",
        "\n",
        "#Print the coefficient in front of t_hat\n",
        "print(f\"SL2S estimator is {reg2.coef_[0].round(2)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSDFK9tXpdWd"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "We get exactly the same estimate!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su52EdaqpdWd"
      },
      "source": [
        "### 3.  Compare your results with Python function IV2SLS from linearmodels package. What can you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8MyJrbTpdWd",
        "outputId": "1e19a3d7-5169-4405-afa7-08a087248fa3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>IV-2SLS Estimation Summary</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>-4.4944</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>-4.4962</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>       <td>3010</td>       <th>  F-statistic:       </th> <td>7.3325</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, Nov 04 2022</td> <th>  P-value (F-stat)   </th> <td>0.0068</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>15:56:04</td>     <th>  Distribution:      </th> <td>chi2(1)</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cov. Estimator:</th>      <td>unadjusted</td>    <th>                     </th>    <td></td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th></th>                          <td></td>         <th>                     </th>    <td></td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<caption>Parameter Estimates</caption>\n",
              "<tr>\n",
              "    <td></td>    <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th>  <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>  <td>-2606.0</td>   <td>1175.6</td>   <td>-2.2167</td> <td>0.0266</td>   <td>-4910.3</td>  <td>-301.83</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>educ</th>   <td>240.01</td>    <td>88.634</td>   <td>2.7079</td>  <td>0.0068</td>   <td>66.288</td>   <td>413.73</td> \n",
              "</tr>\n",
              "</table><br/><br/>Endogenous: educ<br/>Instruments: nearc2<br/>Unadjusted Covariance (Homoskedastic)<br/>Debiased: False<br/>id: 0x12ddbe640"
            ],
            "text/plain": [
              "                          IV-2SLS Estimation Summary                          \n",
              "==============================================================================\n",
              "Dep. Variable:                   wage   R-squared:                     -4.4944\n",
              "Estimator:                    IV-2SLS   Adj. R-squared:                -4.4962\n",
              "No. Observations:                3010   F-statistic:                    7.3325\n",
              "Date:                Fri, Nov 04 2022   P-value (F-stat)                0.0068\n",
              "Time:                        15:56:04   Distribution:                  chi2(1)\n",
              "Cov. Estimator:            unadjusted                                         \n",
              "                                                                              \n",
              "                             Parameter Estimates                              \n",
              "==============================================================================\n",
              "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
              "------------------------------------------------------------------------------\n",
              "const         -2606.0     1175.6    -2.2167     0.0266     -4910.3     -301.83\n",
              "educ           240.01     88.634     2.7079     0.0068      66.288      413.73\n",
              "==============================================================================\n",
              "\n",
              "Endogenous: educ\n",
              "Instruments: nearc2\n",
              "Unadjusted Covariance (Homoskedastic)\n",
              "Debiased: False\n",
              "IVResults, id: 0x12ddbe640"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#We add a constant to the dataset (this is going to be the intercept term of the model)\n",
        "df = df.assign(const = 1)\n",
        "IV2SLS(dependent = df.wage, #outcome\n",
        "       endog = df.educ, #treatment\n",
        "       exog = df.const, #we just add a constant as covariate\n",
        "       instruments = df.nearc2 #Instrument\n",
        "      ).fit(cov_type = \"unadjusted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9mJZ02ypdWd"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "We get exactly the same estimate. Python method also provides a confidence interval and p-value, suggesting that the effect is significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvd8BpmNpdWd"
      },
      "source": [
        "# Exercise 4 : adding covariates to the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONfn_xcRpdWd"
      },
      "source": [
        "For this exercice, we do not assume instrumental uncondoundedness anymore, but instrumental conditional uncondoundedness. We will encompass the role of living in the South (variable south) and of ethnicity (variable black) in our models. The variables should be added to both models (model for treatment and model for outcome)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl3qDZTMpdWd"
      },
      "source": [
        "### 1.  Adapt SL2S to account for the covariates. What do you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaUKkcXOpdWd",
        "outputId": "952859da-bb40-439f-bb9a-3778aa35f437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SL2S estimator is [ 89.6  270.69 278.48].\n"
          ]
        }
      ],
      "source": [
        "##First stage : regress treatment and covariables on instrument.\n",
        "reg1 = LinearRegression().fit(df_binary[[\"nearc2\",\"south\",\"black\"]], df_binary[\"educ\"])\n",
        "\n",
        "##Second stage : regress outcome on the proxy for treatment and the covariables derived at first stage.\n",
        "#Create a new column containing the proxy for treatment inferred from reg1\n",
        "df_binary = df_binary.assign(t_hat = reg1.predict(df_binary[[\"nearc2\",\"south\",\"black\"]]))\n",
        "#Regress outcome of t_hat\n",
        "reg2 = LinearRegression().fit(df_binary[[\"south\",\"black\", \"t_hat\"]], df_binary[\"wage\"])\n",
        "#Print the coefficient in front of t_hat\n",
        "\n",
        "print(f\"SL2S estimator is {reg2.coef_.round(2)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15I2ie6DpdWe"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "The estimate we get for ATE is slightly higher (30 cents/hour) when accounting for the covariates, suggesting the counfounding bias tended to lead to underestimation of the true effect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP5vPNUdpdWe"
      },
      "source": [
        "### 2.  Compare your results with Python function IV2SLS from linearmodels package. What do you conclude?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qqoPnvNpdWe",
        "outputId": "1c081124-c9c2-41c1-c267-c30e313c1bd8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>IV-2SLS Estimation Summary</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>wage</td>       <th>  R-squared:         </th> <td>-6.0579</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th> <td>-6.0649</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>       <td>3010</td>       <th>  F-statistic:       </th> <td>47.869</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Fri, Nov 04 2022</td> <th>  P-value (F-stat)   </th> <td>0.0000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>15:58:19</td>     <th>  Distribution:      </th> <td>chi2(3)</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Cov. Estimator:</th>      <td>unadjusted</td>    <th>                     </th>    <td></td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th></th>                          <td></td>         <th>                     </th>    <td></td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<caption>Parameter Estimates</caption>\n",
              "<tr>\n",
              "    <td></td>    <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th>  <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>  <td>-3215.8</td>   <td>1988.6</td>   <td>-1.6171</td> <td>0.1059</td>   <td>-7113.3</td>  <td>681.80</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>south</th>  <td>89.604</td>    <td>100.75</td>   <td>0.8894</td>  <td>0.3738</td>   <td>-107.87</td>  <td>287.07</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>black</th>  <td>270.69</td>    <td>208.41</td>   <td>1.2988</td>  <td>0.1940</td>   <td>-137.80</td>  <td>679.17</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>educ</th>   <td>278.48</td>    <td>143.35</td>   <td>1.9427</td>  <td>0.0521</td>   <td>-2.4759</td>  <td>559.44</td> \n",
              "</tr>\n",
              "</table><br/><br/>Endogenous: educ<br/>Instruments: nearc2<br/>Unadjusted Covariance (Homoskedastic)<br/>Debiased: False<br/>id: 0x12df65fa0"
            ],
            "text/plain": [
              "                          IV-2SLS Estimation Summary                          \n",
              "==============================================================================\n",
              "Dep. Variable:                   wage   R-squared:                     -6.0579\n",
              "Estimator:                    IV-2SLS   Adj. R-squared:                -6.0649\n",
              "No. Observations:                3010   F-statistic:                    47.869\n",
              "Date:                Fri, Nov 04 2022   P-value (F-stat)                0.0000\n",
              "Time:                        15:58:19   Distribution:                  chi2(3)\n",
              "Cov. Estimator:            unadjusted                                         \n",
              "                                                                              \n",
              "                             Parameter Estimates                              \n",
              "==============================================================================\n",
              "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
              "------------------------------------------------------------------------------\n",
              "const         -3215.8     1988.6    -1.6171     0.1059     -7113.3      681.80\n",
              "south          89.604     100.75     0.8894     0.3738     -107.87      287.07\n",
              "black          270.69     208.41     1.2988     0.1940     -137.80      679.17\n",
              "educ           278.48     143.35     1.9427     0.0521     -2.4759      559.44\n",
              "==============================================================================\n",
              "\n",
              "Endogenous: educ\n",
              "Instruments: nearc2\n",
              "Unadjusted Covariance (Homoskedastic)\n",
              "Debiased: False\n",
              "IVResults, id: 0x12df65fa0"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.assign(const = 1)\n",
        "IV2SLS(dependent = df.wage, #Outcome\n",
        "       endog = df.educ, #Treatment\n",
        "       exog = df[[\"const\",\"south\",\"black\"]], #Covariates (including constant)\n",
        "       instruments = df.nearc2 #Instrument\n",
        "      ).fit(cov_type = \"unadjusted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHj589_EpdWe"
      },
      "source": [
        "**Answer**\n",
        "\n",
        "We get exactly the same estimates, except that now the confidence interval contains zero; so that we do not have enough information to conclude at a significant effect."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}